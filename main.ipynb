{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_=True\n",
    "args = dict(mode='rgb', \n",
    "            train=True, \n",
    "            comp_info='charades_PDAN', \n",
    "            rgb_model_file=None, \n",
    "            flow_model_file=None, \n",
    "            gpu='0', dataset='charades', \n",
    "            rgb_root='../I3D_Feature_Extraction_resnet-main/output/Charades_v1_480', \n",
    "            flow_root='no_root', type='original', lr='0.0001', \n",
    "            epoch='100', model='PDAN', APtype='map', randomseed='False', load_model='False', \n",
    "            batch_size='32', num_channel='512', run_mode='False', feat='False',\n",
    "            early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_[:, 0:1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 47])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_[:, 0:1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 157, 47])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_SEED!!!: 0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# sys.path.append('/data/stars/user/rdai/PhD_work/Graph_net')\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# set random seed\n",
    "if args['randomseed']==\"False\":\n",
    "    SEED = 0\n",
    "elif args['randomseed']==\"True\":\n",
    "    SEED = random.randint(1, 100000)\n",
    "else:\n",
    "    SEED = int(args['randomseed'])\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "print('Random_SEED!!!:', SEED)\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import json\n",
    "\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "\n",
    "from utils import *\n",
    "\n",
    "\n",
    "if str(args['APtype']) == 'wap':\n",
    "    pass\n",
    "    #from wapmeter import APMeter\n",
    "elif str(args['APtype']) == 'map':\n",
    "    from apmeter import APMeter\n",
    "\n",
    "\n",
    "batch_size = int(args['batch_size'])\n",
    "\n",
    "\n",
    "from charades_i3d_per_video import MultiThumos as Dataset\n",
    "from charades_i3d_per_video import mt_collate_fn as collate_fn\n",
    "\n",
    "train_split = './data/charades.json'\n",
    "test_split = './data/charades.json'\n",
    "# print('load feature from:', args.rgb_root)\n",
    "# rgb_root = '/Path/to/charades_feat_rgb'\n",
    "# skeleton_root = '/Path/to/charades_feat_pose'\n",
    "# flow_root = '/Path/to/charades_feat_flow'\n",
    "# rgb_of=[rgb_root,flow_root]\n",
    "classes = 157\n",
    "\n",
    "\n",
    "def load_data(train_split, val_split, root):\n",
    "    # Load Data\n",
    "    print('load data', root)\n",
    "    if len(train_split) > 0:\n",
    "        if str(args['feat']) == '2d':\n",
    "            dataset = Dataset(train_split, 'training', root, batch_size, classes, int(args['pool_step']))\n",
    "        else:\n",
    "            dataset = Dataset(train_split, 'training', root, batch_size, classes)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8,\n",
    "                                                 pin_memory=True, collate_fn=collate_fn)\n",
    "        dataloader.root = root\n",
    "    else:\n",
    "\n",
    "        dataset = None\n",
    "        dataloader = None\n",
    "\n",
    "    if str(args['feat']) == '2d':\n",
    "        val_dataset = Dataset(val_split, 'testing', root, batch_size, classes, int(args['pool_step']))\n",
    "    else:\n",
    "        val_dataset = Dataset(val_split, 'testing', root, batch_size, classes)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=2,\n",
    "                                                 pin_memory=True, collate_fn=collate_fn)\n",
    "    val_dataloader.root = root\n",
    "\n",
    "    dataloaders = {'train': dataloader, 'val': val_dataloader}\n",
    "    datasets = {'train': dataset, 'val': val_dataset}\n",
    "    return dataloaders, datasets\n",
    "\n",
    "\n",
    "# train the model\n",
    "def run(models, criterion, num_epochs=50):\n",
    "    since = time.time()\n",
    "    \n",
    "    if args['early_stopping']:\n",
    "        print('INFO: Initializing early stopping')\n",
    "        early_stopping = EarlyStopping(patience=20)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        probs = []\n",
    "#         for model, gpu, dataloader, optimizer, sched, model_file in models:\n",
    "#             train_map, train_loss = train_step(model, gpu, optimizer, dataloader['train'], epoch)\n",
    "#             prob_val, val_loss, val_map = val_step(model, gpu, dataloader['val'], epoch)\n",
    "#             probs.append(prob_val)\n",
    "#             sched.step(val_loss)\n",
    "#             print('--------Im in for loop')\n",
    "        model, gpu, dataloader, optimizer, sched, model_file = models[0]\n",
    "        train_map, train_loss = train_step(model, gpu, optimizer, dataloader['train'], epoch)\n",
    "        prob_val, val_loss, val_map = val_step(model, gpu, dataloader['val'], epoch)\n",
    "        probs.append(prob_val)\n",
    "        sched.step(val_loss)\n",
    "        \n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_map, epoch)\n",
    "        writer.add_scalar('Accuracy/val',  val_map, epoch)\n",
    "        \n",
    "        print(val_loss.item(), 'val_loss.item()')\n",
    "        #TODO: fix\n",
    "        if args['early_stopping']:\n",
    "            early_stopping(val_loss.item())\n",
    "            if early_stopping.early_stop:\n",
    "                break\n",
    "    \n",
    "    writer.close()\n",
    "\n",
    "def eval_model(model, dataloader, baseline=False):\n",
    "    results = {}\n",
    "    for data in dataloader:\n",
    "        other = data[3]\n",
    "        \n",
    "        outputs, loss, probs, _ = run_network(model[0][0], data, 0, baseline)\n",
    "        fps = outputs.size()[1] / other[1][0]\n",
    "\n",
    "        results[other[0][0]] = (outputs.data.cpu().numpy()[0].tolist(), probs.data.cpu().numpy()[0].tolist(), data[2].numpy()[0].tolist(), float(fps))\n",
    "#         results[other[0][0]] = (outputs.data.cpu().numpy()[0], probs.data.cpu().numpy()[0], data[2].numpy()[0], fps)\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_network(model, data, gpu, epoch=0, baseline=False):\n",
    "    inputs, mask, labels, other = data\n",
    "    # wrap them in Variable\n",
    "    inputs = Variable(inputs.cuda(gpu))\n",
    "    mask = Variable(mask.cuda(gpu))\n",
    "    labels = Variable(labels.cuda(gpu))\n",
    "\n",
    "    mask_list = torch.sum(mask, 1)\n",
    "    mask_new = np.zeros((mask.size()[0], classes, mask.size()[1]))\n",
    "    for i in range(mask.size()[0]):\n",
    "        mask_new[i, :, :int(mask_list[i])] = np.ones((classes, int(mask_list[i])))\n",
    "#     print(mask_new)\n",
    "#     print(np.shape(mask_new))\n",
    "#     print(mask[0, 0:1, :], \"\\n\\n\")\n",
    "    mask_new = torch.from_numpy(mask_new).float()\n",
    "    mask_new = Variable(mask_new.cuda(gpu))\n",
    "    \n",
    "#     global mask_\n",
    "#     mask_ = mask_new\n",
    "#     return 0\n",
    "\n",
    "    inputs = inputs.squeeze(3).squeeze(3)\n",
    "    \n",
    "    activation = model(inputs, mask_new)\n",
    "    #TODO\n",
    "#     activation = model[0](inputs, mask_new)\n",
    "\n",
    "    \n",
    "    outputs_final = activation\n",
    "\n",
    "    #print(\"outputs_final\",outputs_final.size())\n",
    "    outputs_final = outputs_final[-1]\n",
    "    #print(\"outputs_final\",outputs_final.size())\n",
    "    outputs_final = outputs_final.permute(0, 2, 1)  \n",
    "    probs_f = torch.sigmoid(outputs_final) * mask.unsqueeze(2)\n",
    "    loss_f = F.binary_cross_entropy_with_logits(outputs_final, labels, size_average=False)\n",
    "    loss_f = torch.sum(loss_f) / torch.sum(mask)  \n",
    "\n",
    "    loss = loss_f \n",
    "\n",
    "    corr = torch.sum(mask)\n",
    "    tot = torch.sum(mask)\n",
    "\n",
    "    return outputs_final, loss, probs_f, corr / tot\n",
    "\n",
    "\n",
    "def train_step(model, gpu, optimizer, dataloader, epoch):\n",
    "    model.train(True)\n",
    "    tot_loss = 0.0\n",
    "    error = 0.0\n",
    "    num_iter = 0.\n",
    "    apm = APMeter()\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        num_iter += 1\n",
    "\n",
    "        outputs, loss, probs, err = run_network(model, data, gpu, epoch)\n",
    "        apm.add(probs.data.cpu().numpy()[0], data[2].numpy()[0])\n",
    "        error += err.data\n",
    "        tot_loss += loss.data\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if args['APtype'] == 'wap':\n",
    "        train_map = 100 * apm.value()\n",
    "    else:\n",
    "        train_map = 100 * apm.value().mean()\n",
    "    print('train-map:', train_map)\n",
    "    apm.reset()\n",
    "\n",
    "    epoch_loss = tot_loss / num_iter\n",
    "\n",
    "    return train_map, epoch_loss\n",
    "\n",
    "\n",
    "def val_step(model, gpu, dataloader, epoch):\n",
    "    model.train(False)\n",
    "    apm = APMeter()\n",
    "    tot_loss = 0.0\n",
    "    error = 0.0\n",
    "    num_iter = 0.\n",
    "    num_preds = 0\n",
    "\n",
    "    full_probs = {}\n",
    "\n",
    "    # Iterate over data.\n",
    "    for data in dataloader:\n",
    "        num_iter += 1\n",
    "        other = data[3]\n",
    "\n",
    "        outputs, loss, probs, err = run_network(model, data, gpu, epoch)\n",
    "\n",
    "        apm.add(probs.data.cpu().numpy()[0], data[2].numpy()[0])\n",
    "\n",
    "        error += err.data\n",
    "        tot_loss += loss.data\n",
    "\n",
    "        probs = probs.squeeze()\n",
    "\n",
    "        full_probs[other[0][0]] = probs.data.cpu().numpy().T\n",
    "\n",
    "    epoch_loss = tot_loss / num_iter\n",
    "\n",
    "\n",
    "    val_map = torch.sum(100 * apm.value()) / torch.nonzero(100 * apm.value()).size()[0]\n",
    "    print('val-map:', val_map)\n",
    "#     print(100 * apm.value())\n",
    "    apm.reset()\n",
    "\n",
    "    return full_probs, epoch_loss, val_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32\n",
      "cuda_avail True\n",
      "load data ../I3D_Feature_Extraction_resnet-main/output/Charades_v1_480\n",
      "split!!!! training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9848/9848 [00:07<00:00, 1329.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split!!!! testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9848/9848 [00:01<00:00, 5323.19it/s]\n",
      "C:\\Users\\David\\Desktop\\har\\PDAN\\PDAN.py:98: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.key_conv.weight, mode='fan_out')\n",
      "C:\\Users\\David\\Desktop\\har\\PDAN\\PDAN.py:99: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.value_conv.weight, mode='fan_out')\n",
      "C:\\Users\\David\\Desktop\\har\\PDAN\\PDAN.py:100: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.query_conv.weight, mode='fan_out')\n",
      "C:\\Users\\David\\Desktop\\har\\PDAN\\PDAN.py:101: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(self.rel_t, 0, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are processing PDAN_original\n",
      "pytorch_total_params 6382749\n",
      "stage: 1 block: 5 num_channel: 512 input_channnel: 2048 num_classes: 157\n",
      "pytorch_total_params 6382749\n",
      "num_channel: 512 input_channnel: 2048 num_classes: 157\n",
      "lr 0.0001\n",
      "<class 'torch.nn.parallel.data_parallel.DataParallel'> type model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "\n",
    "args['model'] = 'PDAN'\n",
    "print('batch_size:', batch_size)\n",
    "print('cuda_avail', torch.cuda.is_available())\n",
    "\n",
    "dataloaders, datasets = load_data(train_split, test_split, args['rgb_root'])\n",
    "\n",
    "if args['train']:\n",
    "    num_channel = args['num_channel']\n",
    "    input_channnel = 2048\n",
    "\n",
    "    num_classes = classes\n",
    "    mid_channel=int(args['num_channel'])\n",
    "\n",
    "    if args['model']==\"PDAN\":\n",
    "        print(\"you are processing PDAN_original\")\n",
    "        from PDAN import PDAN\n",
    "        # rgb_model = Net(mid_channel, input_channnel, classes)\n",
    "        stage=1\n",
    "        block=5\n",
    "        num_channel=512\n",
    "        input_channnel=2048\n",
    "        num_classes=classes\n",
    "        rgb_model = PDAN(stage, block, num_channel, input_channnel, num_classes)\n",
    "        pytorch_total_params = sum(p.numel() for p in rgb_model.parameters() if p.requires_grad)\n",
    "        print('pytorch_total_params', pytorch_total_params)\n",
    "        #exit()\n",
    "        print ('stage:', stage, 'block:', block, 'num_channel:', num_channel, 'input_channnel:', input_channnel,\n",
    "               'num_classes:', num_classes)\n",
    "\n",
    "\n",
    "    rgb_model=torch.nn.DataParallel(rgb_model)\n",
    "\n",
    "    if args['load_model']!= \"False\":\n",
    "        state_dict = torch.load(str(args['load_model']))\n",
    "\n",
    "    pytorch_total_params = sum(p.numel() for p in rgb_model.parameters() if p.requires_grad)\n",
    "    print('pytorch_total_params', pytorch_total_params)\n",
    "    print('num_channel:', num_channel, 'input_channnel:', input_channnel,'num_classes:', num_classes)\n",
    "    rgb_model.cuda()\n",
    "\n",
    "    criterion = nn.NLLLoss(reduce=False)\n",
    "    lr = float(args['lr'])\n",
    "    print('lr', lr)\n",
    "    optimizer = optim.Adam(rgb_model.parameters(), lr=lr)\n",
    "    lr_sched = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=8, verbose=True)\n",
    "    print(type(rgb_model), 'type model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): PDAN(\n",
       "    (stage1): SSPDAN(\n",
       "      (conv_1x1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "      (layers): ModuleList(\n",
       "        (0): PDAN_Block(\n",
       "          (conv_attention): DAL(\n",
       "            (key_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (query_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (value_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (conv_1x1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (1): PDAN_Block(\n",
       "          (conv_attention): DAL(\n",
       "            (key_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (query_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (value_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (conv_1x1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (2): PDAN_Block(\n",
       "          (conv_attention): DAL(\n",
       "            (key_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (query_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (value_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (conv_1x1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (3): PDAN_Block(\n",
       "          (conv_attention): DAL(\n",
       "            (key_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (query_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (value_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (conv_1x1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (4): PDAN_Block(\n",
       "          (conv_attention): DAL(\n",
       "            (key_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (query_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (value_conv): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (conv_1x1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (conv_out): Conv1d(512, 157, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (stages): ModuleList()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "C:\\Users\\David\\Desktop\\har\\PDAN\\apmeter.py:108: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  rg = torch.range(1, self.scores.size(0)).float()\n",
      "C:\\Users\\David\\Desktop\\har\\PDAN\\apmeter.py:136: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ..\\aten\\src\\ATen/native/IndexingUtils.h:30.)\n",
      "  ap[k] = precision[truth.byte()].sum() / max(truth.sum(), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-map: tensor(2.1128)\n",
      "val-map: tensor(5.0986)\n",
      "15.466021537780762 val_loss.item()\n",
      "Epoch 1/99\n",
      "----------\n",
      "train-map: tensor(4.6105)\n",
      "val-map: tensor(6.6886)\n",
      "14.98080062866211 val_loss.item()\n",
      "Epoch 2/99\n",
      "----------\n",
      "train-map: tensor(5.4792)\n",
      "val-map: tensor(7.6181)\n",
      "15.067852020263672 val_loss.item()\n",
      "Epoch 3/99\n",
      "----------\n",
      "train-map: tensor(7.5792)\n",
      "val-map: tensor(8.1531)\n",
      "14.860237121582031 val_loss.item()\n",
      "Epoch 4/99\n",
      "----------\n",
      "train-map: tensor(7.8553)\n",
      "val-map: tensor(8.7103)\n",
      "14.721099853515625 val_loss.item()\n",
      "Epoch 5/99\n",
      "----------\n",
      "train-map: tensor(8.9429)\n",
      "val-map: tensor(9.0770)\n",
      "14.558691024780273 val_loss.item()\n",
      "Epoch 6/99\n",
      "----------\n",
      "train-map: tensor(10.4582)\n",
      "val-map: tensor(9.3920)\n",
      "14.588655471801758 val_loss.item()\n",
      "Epoch 7/99\n",
      "----------\n",
      "train-map: tensor(11.4889)\n",
      "val-map: tensor(9.6692)\n",
      "14.410964012145996 val_loss.item()\n",
      "Epoch 8/99\n",
      "----------\n",
      "train-map: tensor(9.9026)\n",
      "val-map: tensor(9.8736)\n",
      "14.64443588256836 val_loss.item()\n",
      "Epoch 9/99\n",
      "----------\n",
      "train-map: tensor(12.5856)\n",
      "val-map: tensor(10.0268)\n",
      "14.372509002685547 val_loss.item()\n",
      "Epoch 10/99\n",
      "----------\n",
      "train-map: tensor(12.5926)\n",
      "val-map: tensor(10.0515)\n",
      "14.441746711730957 val_loss.item()\n",
      "Epoch 11/99\n",
      "----------\n",
      "train-map: tensor(14.1863)\n",
      "val-map: tensor(10.1849)\n",
      "14.45200252532959 val_loss.item()\n",
      "Epoch 12/99\n",
      "----------\n",
      "train-map: tensor(13.2257)\n",
      "val-map: tensor(10.3118)\n",
      "14.610413551330566 val_loss.item()\n",
      "Epoch 13/99\n",
      "----------\n",
      "train-map: tensor(16.9235)\n",
      "val-map: tensor(10.4688)\n",
      "14.549148559570312 val_loss.item()\n",
      "Epoch 14/99\n",
      "----------\n",
      "train-map: tensor(19.7118)\n",
      "val-map: tensor(10.3778)\n",
      "14.874777793884277 val_loss.item()\n",
      "Epoch 15/99\n",
      "----------\n",
      "train-map: tensor(21.4756)\n",
      "val-map: tensor(10.4641)\n",
      "14.611352920532227 val_loss.item()\n",
      "Epoch 16/99\n",
      "----------\n",
      "train-map: tensor(16.0824)\n",
      "val-map: tensor(10.5416)\n",
      "14.689932823181152 val_loss.item()\n",
      "Epoch 17/99\n",
      "----------\n",
      "train-map: tensor(20.9643)\n",
      "val-map: tensor(10.3948)\n",
      "14.749245643615723 val_loss.item()\n",
      "Epoch 18/99\n",
      "----------\n",
      "train-map: tensor(20.8567)\n",
      "val-map: tensor(10.6217)\n",
      "Epoch    19: reducing learning rate of group 0 to 5.0000e-05.\n",
      "14.811728477478027 val_loss.item()\n",
      "Epoch 19/99\n",
      "----------\n",
      "train-map: tensor(26.4976)\n",
      "val-map: tensor(10.4759)\n",
      "15.003722190856934 val_loss.item()\n",
      "Epoch 20/99\n",
      "----------\n",
      "train-map: tensor(23.9553)\n",
      "val-map: tensor(10.5045)\n",
      "14.881355285644531 val_loss.item()\n",
      "Epoch 21/99\n",
      "----------\n",
      "train-map: tensor(28.4648)\n",
      "val-map: tensor(10.5291)\n",
      "15.138092994689941 val_loss.item()\n",
      "Epoch 22/99\n",
      "----------\n",
      "train-map: tensor(27.8698)\n",
      "val-map: tensor(10.3357)\n",
      "15.2105712890625 val_loss.item()\n",
      "Epoch 23/99\n",
      "----------\n",
      "train-map: tensor(26.0792)\n",
      "val-map: tensor(10.3490)\n",
      "15.211552619934082 val_loss.item()\n",
      "Epoch 24/99\n",
      "----------\n",
      "train-map: tensor(27.6994)\n",
      "val-map: tensor(10.3420)\n",
      "15.2578706741333 val_loss.item()\n",
      "Epoch 25/99\n",
      "----------\n",
      "train-map: tensor(29.9946)\n",
      "val-map: tensor(10.1910)\n",
      "15.41401481628418 val_loss.item()\n",
      "Epoch 26/99\n",
      "----------\n",
      "train-map: tensor(31.3825)\n",
      "val-map: tensor(10.1055)\n",
      "15.444536209106445 val_loss.item()\n",
      "Epoch 27/99\n",
      "----------\n",
      "train-map: tensor(32.4295)\n",
      "val-map: tensor(10.0975)\n",
      "Epoch    28: reducing learning rate of group 0 to 2.5000e-05.\n",
      "15.705211639404297 val_loss.item()\n",
      "Epoch 28/99\n",
      "----------\n",
      "train-map: tensor(34.9005)\n",
      "val-map: tensor(10.1348)\n",
      "15.727924346923828 val_loss.item()\n",
      "Epoch 29/99\n",
      "----------\n",
      "train-map: tensor(36.3859)\n",
      "val-map: tensor(10.1990)\n",
      "15.774215698242188 val_loss.item()\n",
      "Epoch 30/99\n",
      "----------\n",
      "train-map: tensor(35.2727)\n",
      "val-map: tensor(10.1616)\n",
      "15.819565773010254 val_loss.item()\n",
      "Epoch 31/99\n",
      "----------\n",
      "train-map: tensor(33.1043)\n",
      "val-map: tensor(10.1584)\n",
      "15.982281684875488 val_loss.item()\n",
      "Epoch 32/99\n",
      "----------\n",
      "train-map: tensor(34.8164)\n",
      "val-map: tensor(10.0317)\n",
      "15.85002326965332 val_loss.item()\n",
      "Epoch 33/99\n",
      "----------\n",
      "train-map: tensor(35.0433)\n",
      "val-map: tensor(9.9923)\n",
      "15.905130386352539 val_loss.item()\n",
      "Epoch 34/99\n",
      "----------\n",
      "train-map: tensor(36.0097)\n",
      "val-map: tensor(10.0362)\n",
      "15.970903396606445 val_loss.item()\n",
      "Epoch 35/99\n",
      "----------\n",
      "train-map: tensor(33.5490)\n",
      "val-map: tensor(10.1088)\n",
      "16.130306243896484 val_loss.item()\n",
      "Epoch 36/99\n",
      "----------\n",
      "train-map: tensor(37.3793)\n",
      "val-map: tensor(10.0146)\n",
      "Epoch    37: reducing learning rate of group 0 to 1.2500e-05.\n",
      "16.113418579101562 val_loss.item()\n",
      "Epoch 37/99\n",
      "----------\n",
      "train-map: tensor(35.3693)\n",
      "val-map: tensor(9.9717)\n",
      "16.28136444091797 val_loss.item()\n",
      "Epoch 38/99\n",
      "----------\n",
      "train-map: tensor(37.3680)\n",
      "val-map: tensor(9.9025)\n",
      "16.320415496826172 val_loss.item()\n",
      "Epoch 39/99\n",
      "----------\n",
      "train-map: tensor(34.8179)\n",
      "val-map: tensor(9.8871)\n",
      "16.396909713745117 val_loss.item()\n",
      "Epoch 40/99\n",
      "----------\n",
      "train-map: tensor(36.2116)\n",
      "val-map: tensor(9.9107)\n",
      "16.274694442749023 val_loss.item()\n",
      "Epoch 41/99\n",
      "----------\n",
      "train-map: tensor(38.4426)\n",
      "val-map: tensor(9.8719)\n",
      "16.425579071044922 val_loss.item()\n",
      "Epoch 42/99\n",
      "----------\n",
      "train-map: tensor(39.4125)\n",
      "val-map: tensor(9.8986)\n",
      "16.37924575805664 val_loss.item()\n",
      "Epoch 43/99\n",
      "----------\n",
      "train-map: tensor(34.5140)\n",
      "val-map: tensor(9.8690)\n",
      "16.489669799804688 val_loss.item()\n",
      "Epoch 44/99\n",
      "----------\n",
      "train-map: tensor(34.9102)\n",
      "val-map: tensor(9.8759)\n",
      "16.62560272216797 val_loss.item()\n",
      "Epoch 45/99\n",
      "----------\n",
      "train-map: tensor(40.1417)\n",
      "val-map: tensor(9.8348)\n",
      "Epoch    46: reducing learning rate of group 0 to 6.2500e-06.\n",
      "16.649633407592773 val_loss.item()\n",
      "Epoch 46/99\n",
      "----------\n",
      "train-map: tensor(41.6679)\n",
      "val-map: tensor(9.8821)\n",
      "16.57779884338379 val_loss.item()\n",
      "Epoch 47/99\n",
      "----------\n",
      "train-map: tensor(38.8257)\n",
      "val-map: tensor(9.8426)\n",
      "16.639930725097656 val_loss.item()\n",
      "Epoch 48/99\n",
      "----------\n",
      "train-map: tensor(36.3060)\n",
      "val-map: tensor(9.8145)\n",
      "16.651309967041016 val_loss.item()\n",
      "Epoch 49/99\n",
      "----------\n",
      "train-map: tensor(41.5422)\n",
      "val-map: tensor(9.8049)\n",
      "16.67936897277832 val_loss.item()\n",
      "Epoch 50/99\n",
      "----------\n",
      "train-map: tensor(38.2086)\n",
      "val-map: tensor(9.7864)\n",
      "16.708356857299805 val_loss.item()\n",
      "Epoch 51/99\n",
      "----------\n",
      "train-map: tensor(41.5889)\n",
      "val-map: tensor(9.8008)\n",
      "16.702905654907227 val_loss.item()\n",
      "Epoch 52/99\n",
      "----------\n",
      "train-map: tensor(39.4809)\n",
      "val-map: tensor(9.7839)\n",
      "16.686922073364258 val_loss.item()\n",
      "Epoch 53/99\n",
      "----------\n",
      "train-map: tensor(39.5801)\n",
      "val-map: tensor(9.7950)\n",
      "16.745162963867188 val_loss.item()\n",
      "Epoch 54/99\n",
      "----------\n",
      "train-map: tensor(38.6725)\n",
      "val-map: tensor(9.7694)\n",
      "Epoch    55: reducing learning rate of group 0 to 3.1250e-06.\n",
      "16.768543243408203 val_loss.item()\n",
      "Epoch 55/99\n",
      "----------\n",
      "train-map: tensor(38.6387)\n",
      "val-map: tensor(9.7987)\n",
      "16.866525650024414 val_loss.item()\n",
      "Epoch 56/99\n",
      "----------\n",
      "train-map: tensor(39.2971)\n",
      "val-map: tensor(9.7744)\n",
      "16.816104888916016 val_loss.item()\n",
      "Epoch 57/99\n",
      "----------\n",
      "train-map: tensor(40.0586)\n",
      "val-map: tensor(9.7616)\n",
      "16.881622314453125 val_loss.item()\n",
      "Epoch 58/99\n",
      "----------\n",
      "train-map: tensor(38.4827)\n",
      "val-map: tensor(9.7767)\n",
      "16.841764450073242 val_loss.item()\n",
      "Epoch 59/99\n",
      "----------\n",
      "train-map: tensor(41.3497)\n",
      "val-map: tensor(9.7513)\n",
      "16.825902938842773 val_loss.item()\n",
      "Epoch 60/99\n",
      "----------\n",
      "train-map: tensor(38.6348)\n",
      "val-map: tensor(9.7601)\n",
      "16.849517822265625 val_loss.item()\n",
      "Epoch 61/99\n",
      "----------\n",
      "train-map: tensor(44.1696)\n",
      "val-map: tensor(9.7456)\n",
      "16.916484832763672 val_loss.item()\n",
      "Epoch 62/99\n",
      "----------\n",
      "train-map: tensor(39.9392)\n",
      "val-map: tensor(9.7516)\n",
      "16.858182907104492 val_loss.item()\n",
      "Epoch 63/99\n",
      "----------\n",
      "train-map: tensor(41.4686)\n",
      "val-map: tensor(9.7621)\n",
      "Epoch    64: reducing learning rate of group 0 to 1.5625e-06.\n",
      "16.8969669342041 val_loss.item()\n",
      "Epoch 64/99\n",
      "----------\n",
      "train-map: tensor(39.9592)\n",
      "val-map: tensor(9.7466)\n",
      "16.90519905090332 val_loss.item()\n",
      "Epoch 65/99\n",
      "----------\n",
      "train-map: tensor(39.3982)\n",
      "val-map: tensor(9.7349)\n",
      "16.916425704956055 val_loss.item()\n",
      "Epoch 66/99\n",
      "----------\n",
      "train-map: tensor(40.1427)\n",
      "val-map: tensor(9.7278)\n",
      "16.903488159179688 val_loss.item()\n",
      "Epoch 67/99\n",
      "----------\n",
      "train-map: tensor(40.0314)\n",
      "val-map: tensor(9.7613)\n",
      "16.95248794555664 val_loss.item()\n",
      "Epoch 68/99\n",
      "----------\n",
      "train-map: tensor(42.2061)\n",
      "val-map: tensor(9.7369)\n",
      "16.9365234375 val_loss.item()\n",
      "Epoch 69/99\n",
      "----------\n",
      "train-map: tensor(42.2462)\n",
      "val-map: tensor(9.7339)\n",
      "16.949392318725586 val_loss.item()\n",
      "Epoch 70/99\n",
      "----------\n",
      "train-map: tensor(38.1317)\n",
      "val-map: tensor(9.7289)\n",
      "16.924776077270508 val_loss.item()\n",
      "Epoch 71/99\n",
      "----------\n",
      "train-map: tensor(40.4598)\n",
      "val-map: tensor(9.7347)\n",
      "16.951866149902344 val_loss.item()\n",
      "Epoch 72/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-map: tensor(38.9095)\n",
      "val-map: tensor(9.7312)\n",
      "Epoch    73: reducing learning rate of group 0 to 7.8125e-07.\n",
      "16.968809127807617 val_loss.item()\n",
      "Epoch 73/99\n",
      "----------\n",
      "train-map: tensor(42.2233)\n",
      "val-map: tensor(9.7484)\n",
      "16.96849250793457 val_loss.item()\n",
      "Epoch 74/99\n",
      "----------\n",
      "train-map: tensor(37.4808)\n",
      "val-map: tensor(9.7470)\n",
      "16.978464126586914 val_loss.item()\n",
      "Epoch 75/99\n",
      "----------\n",
      "train-map: tensor(43.4800)\n",
      "val-map: tensor(9.7342)\n",
      "16.980920791625977 val_loss.item()\n",
      "Epoch 76/99\n",
      "----------\n",
      "train-map: tensor(40.6734)\n",
      "val-map: tensor(9.7205)\n",
      "16.963314056396484 val_loss.item()\n",
      "Epoch 77/99\n",
      "----------\n",
      "train-map: tensor(40.8955)\n",
      "val-map: tensor(9.7313)\n",
      "16.97983741760254 val_loss.item()\n",
      "Epoch 78/99\n",
      "----------\n",
      "train-map: tensor(39.7594)\n",
      "val-map: tensor(9.7284)\n",
      "16.997833251953125 val_loss.item()\n",
      "Epoch 79/99\n",
      "----------\n",
      "train-map: tensor(38.9177)\n",
      "val-map: tensor(9.7276)\n",
      "16.991317749023438 val_loss.item()\n",
      "Epoch 80/99\n",
      "----------\n",
      "train-map: tensor(40.7283)\n",
      "val-map: tensor(9.7108)\n",
      "16.964263916015625 val_loss.item()\n",
      "Epoch 81/99\n",
      "----------\n",
      "train-map: tensor(41.3780)\n",
      "val-map: tensor(9.7270)\n",
      "Epoch    82: reducing learning rate of group 0 to 3.9063e-07.\n",
      "16.993736267089844 val_loss.item()\n",
      "Epoch 82/99\n",
      "----------\n",
      "train-map: tensor(40.7737)\n",
      "val-map: tensor(9.7225)\n",
      "16.988056182861328 val_loss.item()\n",
      "Epoch 83/99\n",
      "----------\n",
      "train-map: tensor(39.9819)\n",
      "val-map: tensor(9.7204)\n",
      "16.993083953857422 val_loss.item()\n",
      "Epoch 84/99\n",
      "----------\n",
      "train-map: tensor(44.2361)\n",
      "val-map: tensor(9.7273)\n",
      "17.002710342407227 val_loss.item()\n",
      "Epoch 85/99\n",
      "----------\n",
      "train-map: tensor(42.7130)\n",
      "val-map: tensor(9.7236)\n",
      "17.002811431884766 val_loss.item()\n",
      "Epoch 86/99\n",
      "----------\n",
      "train-map: tensor(40.6797)\n",
      "val-map: tensor(9.7222)\n",
      "17.019712448120117 val_loss.item()\n",
      "Epoch 87/99\n",
      "----------\n",
      "train-map: tensor(42.4613)\n",
      "val-map: tensor(9.7229)\n",
      "17.00692367553711 val_loss.item()\n",
      "Epoch 88/99\n",
      "----------\n",
      "train-map: tensor(41.4467)\n",
      "val-map: tensor(9.7221)\n",
      "16.984851837158203 val_loss.item()\n",
      "Epoch 89/99\n",
      "----------\n",
      "train-map: tensor(40.8119)\n",
      "val-map: tensor(9.7250)\n",
      "17.004806518554688 val_loss.item()\n",
      "Epoch 90/99\n",
      "----------\n",
      "train-map: tensor(42.5820)\n",
      "val-map: tensor(9.7192)\n",
      "Epoch    91: reducing learning rate of group 0 to 1.9531e-07.\n",
      "17.00855827331543 val_loss.item()\n",
      "Epoch 91/99\n",
      "----------\n",
      "train-map: tensor(38.2852)\n",
      "val-map: tensor(9.7252)\n",
      "17.00836181640625 val_loss.item()\n",
      "Epoch 92/99\n",
      "----------\n",
      "train-map: tensor(37.5441)\n",
      "val-map: tensor(9.7188)\n",
      "17.00900650024414 val_loss.item()\n",
      "Epoch 93/99\n",
      "----------\n",
      "train-map: tensor(39.5592)\n",
      "val-map: tensor(9.7196)\n",
      "16.998641967773438 val_loss.item()\n",
      "Epoch 94/99\n",
      "----------\n",
      "train-map: tensor(43.6614)\n",
      "val-map: tensor(9.7225)\n",
      "17.00225830078125 val_loss.item()\n",
      "Epoch 95/99\n",
      "----------\n",
      "train-map: tensor(41.5141)\n",
      "val-map: tensor(9.7189)\n",
      "17.01445198059082 val_loss.item()\n",
      "Epoch 96/99\n",
      "----------\n",
      "train-map: tensor(43.0965)\n",
      "val-map: tensor(9.7213)\n",
      "17.00580406188965 val_loss.item()\n",
      "Epoch 97/99\n",
      "----------\n",
      "train-map: tensor(41.9118)\n",
      "val-map: tensor(9.7193)\n",
      "17.0126895904541 val_loss.item()\n",
      "Epoch 98/99\n",
      "----------\n",
      "train-map: tensor(41.1887)\n",
      "val-map: tensor(9.7169)\n",
      "17.012310028076172 val_loss.item()\n",
      "Epoch 99/99\n",
      "----------\n",
      "train-map: tensor(42.6783)\n",
      "val-map: tensor(9.7202)\n",
      "Epoch   100: reducing learning rate of group 0 to 9.7656e-08.\n",
      "17.00994300842285 val_loss.item()\n",
      "Wall time: 3h 28min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run([(rgb_model, 0, dataloaders, optimizer, lr_sched, args['comp_info'])], criterion, num_epochs=int(args['epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = eval_model([(rgb_model, 0, dataloaders, optimizer, lr_sched, args['comp_info'])], dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_:\n",
    "    with open('../output_PDAN/results_less_param.txt', 'w') as file:\n",
    "        file.write(json.dumps(results)) # use `json.loads` to do the reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_:\n",
    "    torch.save(rgb_model, '../output_PDAN/rgb_model_less_param.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
